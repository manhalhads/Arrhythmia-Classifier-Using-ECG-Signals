{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqHxjVNGRExp",
        "outputId": "efa2fbe7-354f-4c67-e66e-d3efcc6182b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.13.2)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.3)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.10.5)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, wfdb\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.3 wfdb-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wfdb\n",
        "from scipy.signal import resample\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from wfdb import processing\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "H6nNEykkTsrP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXcKDcrXQqUY",
        "outputId": "4c8bed63-9df8-45e4-a6c8-a80cb4f71c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 2)\n",
            "[   7   83  396  711 1032 1368 1712 2036 2349 2662]\n",
            "['+', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
            "(640, 2)\n",
            "[ 105  234  362  490  619  747  868  987 1107 1229]\n",
            "['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
            "\n",
            "MIT-BIH freq: 360\n",
            "SVDB freq: 128\n",
            "The MIT-BIH dataset has a sample of 360 per second per channel while SVDB dataset has a sample of 128 per second.\n"
          ]
        }
      ],
      "source": [
        "#Loading Datasets (MIT-BIH and Supraventricular Arrhythmia Dataset)\n",
        "\n",
        "# Load record number 100\n",
        "signals_bih, fields_bih = wfdb.rdsamp('101', sampto=1000, pn_dir='mitdb') #loads the ecg signal values - sample 101, from second 0 to second 2.87. 1000/360 = 2.87\n",
        "# Load 5 seconds of data (5 * 128 = 640 samples)\n",
        "signals_sup, fields_sup = wfdb.rdsamp('802', sampto=640, pn_dir='svdb')  # \"svdb\" = supraventricular arrhythmia dataset\n",
        "\n",
        "# Load annotations (beat labels)\n",
        "annotation_bih = wfdb.rdann('101', 'atr', pn_dir='mitdb') #read annotation(label for sample 101)\n",
        "annotation_sup = wfdb.rdann('802', 'atr', pn_dir = 'svdb') #read annotation label for sample 802 for sup dataset\n",
        "\n",
        "print(signals_bih.shape)  # (1000, 2)\n",
        "print(annotation_bih.sample[:10])  # positions of first 10 beats\n",
        "print(annotation_bih.symbol[:10])  # their labels (like 'N', 'V', 'A', etc.)\n",
        "\n",
        "print(signals_sup.shape)  # (1000, 2)\n",
        "print(annotation_sup.sample[:10])  # positions of first 10 beats\n",
        "print(annotation_sup.symbol[:10])  # their labels (like 'N', 'V', 'A', etc.)\n",
        "\n",
        "#signals is a numpy array, fields is a dictionary\n",
        "# fields contains\n",
        "# fs: The sampling frequency of the record.\n",
        "# units: The units for each channel.\n",
        "# sig_name: The signal name for each channel.\n",
        "# comments: Any comments written in the header.\n",
        "print()\n",
        "print(\"MIT-BIH freq:\", fields_bih['fs'])\n",
        "print(\"SVDB freq:\", fields_sup['fs'])\n",
        "print(\"The MIT-BIH dataset has a sample of 360 per second per channel while SVDB dataset has a sample of 128 per second.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resampling SVDB to 360 per second\n",
        "\n",
        "# Function to resample svdb record\n",
        "def resample_svdb_record(rec_name, target_fs=360):\n",
        "    record = wfdb.rdrecord(rec_name, pn_dir='svdb') #Reading record\n",
        "    ann = wfdb.rdann(rec_name, 'atr', pn_dir='svdb') #Getting annotation for record\n",
        "\n",
        "    #Resampling signals and annotations (all channels)\n",
        "    signals_resampled, ann_resampled = processing.resample_multichan(\n",
        "    xs=record.p_signal,\n",
        "    ann=ann,\n",
        "    fs=record.fs,\n",
        "    fs_target=fs_target\n",
        ")\n",
        "    return signals_resampled, ann_resampled\n",
        "\n",
        "#Function to save resampled record to folder\n",
        "def save_resampled_record(signals, annotations, record_name, folder='combined_db', fs=360):\n",
        " #Save the signal\n",
        "  wfdb.wrsamp(\n",
        "        record_name=record_name,\n",
        "        fs=fs,\n",
        "        units=['mV'] * signals.shape[1],\n",
        "        sig_name=[f'ECG{i+1}' for i in range(signals.shape[1])],\n",
        "        p_signal=signals,\n",
        "        write_dir= folder\n",
        "    )\n",
        "\n",
        "  #Save annotations\n",
        "  wfdb.wrann(\n",
        "            record_name=record_name,\n",
        "            extension='atr',\n",
        "            fs=fs,\n",
        "            sample=annotations.sample,\n",
        "            symbol=annotations.symbol,\n",
        "            write_dir = folder\n",
        "        )\n",
        "\n",
        "#Loading record liats of both databases\n",
        "record_list_sup = wfdb.get_record_list('svdb')\n",
        "record_list_mit = wfdb.get_record_list('mitdb')\n",
        "fs_target = 360\n",
        "folder = 'combined_db'\n",
        "os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "\n",
        "# Resample and save all SVDB records\n",
        "print(\"Resampling and saving SVDB records\")\n",
        "for i, rec_name in enumerate(tqdm(record_list_sup)):\n",
        "    try:\n",
        "        signals_resampled, ann_resampled = resample_svdb_record(rec_name, fs_target)\n",
        "        save_resampled_record(signals_resampled, ann_resampled, record_name=f'svdb_360_{i:02d}',folder=folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing record {rec_name}: {e}\")\n"
      ],
      "metadata": {
        "id": "JhuPcH8Pm-2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7a23ca-5418-4d3a-dd98-6cf00a3ee078"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling and saving SVDB records\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78/78 [06:05<00:00,  4.68s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Copying MIT-BIH records into combined_db folder (same format as original)\")\n",
        "wfdb.dl_database('mitdb', dl_dir=folder)\n",
        "\n",
        "print(\"MIT-BIH records successfully downloaded into combined_db\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXYYC2bIIEbr",
        "outputId": "d69f4410-95f0-4be9-9345-9334f02d5e53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying MIT-BIH records into combined_db folder (same format as original)\n",
            "Generating record list for: 100\n",
            "Generating record list for: 101\n",
            "Generating record list for: 102\n",
            "Generating record list for: 103\n",
            "Generating record list for: 104\n",
            "Generating record list for: 105\n",
            "Generating record list for: 106\n",
            "Generating record list for: 107\n",
            "Generating record list for: 108\n",
            "Generating record list for: 109\n",
            "Generating record list for: 111\n",
            "Generating record list for: 112\n",
            "Generating record list for: 113\n",
            "Generating record list for: 114\n",
            "Generating record list for: 115\n",
            "Generating record list for: 116\n",
            "Generating record list for: 117\n",
            "Generating record list for: 118\n",
            "Generating record list for: 119\n",
            "Generating record list for: 121\n",
            "Generating record list for: 122\n",
            "Generating record list for: 123\n",
            "Generating record list for: 124\n",
            "Generating record list for: 200\n",
            "Generating record list for: 201\n",
            "Generating record list for: 202\n",
            "Generating record list for: 203\n",
            "Generating record list for: 205\n",
            "Generating record list for: 207\n",
            "Generating record list for: 208\n",
            "Generating record list for: 209\n",
            "Generating record list for: 210\n",
            "Generating record list for: 212\n",
            "Generating record list for: 213\n",
            "Generating record list for: 214\n",
            "Generating record list for: 215\n",
            "Generating record list for: 217\n",
            "Generating record list for: 219\n",
            "Generating record list for: 220\n",
            "Generating record list for: 221\n",
            "Generating record list for: 222\n",
            "Generating record list for: 223\n",
            "Generating record list for: 228\n",
            "Generating record list for: 230\n",
            "Generating record list for: 231\n",
            "Generating record list for: 232\n",
            "Generating record list for: 233\n",
            "Generating record list for: 234\n",
            "Generating list of all files for: 100\n",
            "Generating list of all files for: 101\n",
            "Generating list of all files for: 102\n",
            "Generating list of all files for: 103\n",
            "Generating list of all files for: 104\n",
            "Generating list of all files for: 105\n",
            "Generating list of all files for: 106\n",
            "Generating list of all files for: 107\n",
            "Generating list of all files for: 108\n",
            "Generating list of all files for: 109\n",
            "Generating list of all files for: 111\n",
            "Generating list of all files for: 112\n",
            "Generating list of all files for: 113\n",
            "Generating list of all files for: 114\n",
            "Generating list of all files for: 115\n",
            "Generating list of all files for: 116\n",
            "Generating list of all files for: 117\n",
            "Generating list of all files for: 118\n",
            "Generating list of all files for: 119\n",
            "Generating list of all files for: 121\n",
            "Generating list of all files for: 122\n",
            "Generating list of all files for: 123\n",
            "Generating list of all files for: 124\n",
            "Generating list of all files for: 200\n",
            "Generating list of all files for: 201\n",
            "Generating list of all files for: 202\n",
            "Generating list of all files for: 203\n",
            "Generating list of all files for: 205\n",
            "Generating list of all files for: 207\n",
            "Generating list of all files for: 208\n",
            "Generating list of all files for: 209\n",
            "Generating list of all files for: 210\n",
            "Generating list of all files for: 212\n",
            "Generating list of all files for: 213\n",
            "Generating list of all files for: 214\n",
            "Generating list of all files for: 215\n",
            "Generating list of all files for: 217\n",
            "Generating list of all files for: 219\n",
            "Generating list of all files for: 220\n",
            "Generating list of all files for: 221\n",
            "Generating list of all files for: 222\n",
            "Generating list of all files for: 223\n",
            "Generating list of all files for: 228\n",
            "Generating list of all files for: 230\n",
            "Generating list of all files for: 231\n",
            "Generating list of all files for: 232\n",
            "Generating list of all files for: 233\n",
            "Generating list of all files for: 234\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "MIT-BIH records successfully downloaded into combined_db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Segment beats in samples\n",
        "\n",
        "def get_beat_boundaries(r_peaks, signal_length):\n",
        "    \"\"\"\n",
        "    Estimate start and end indices of each beat using R-peaks.\n",
        "    Each beat goes from midpoint between previous and current R,\n",
        "    to midpoint between current and next R.\n",
        "    \"\"\"\n",
        "    boundaries = []\n",
        "    for i in range(1, len(r_peaks)-1):\n",
        "        start = int((r_peaks[i-1] + r_peaks[i]) / 2)\n",
        "        end = int((r_peaks[i] + r_peaks[i+1]) / 2)\n",
        "        if start >= 0 and end <= signal_length:\n",
        "            boundaries.append((start, end))\n",
        "    return boundaries\n",
        "\n",
        "\n",
        "\n",
        "combined_db_path = '/content/combined_db'     # folder with all records (.dat, .hea, .atr)\n",
        "output_folder = '/content/segmented_beats'    # folder where segmented beats will be stored\n",
        "\n",
        "# Record list\n",
        "# this finds all the records (e.g. 100, 101, svdb_360_00, etc.)\n",
        "record_list = sorted(list(set([f.split('.')[0] for f in os.listdir(combined_db_path) if f.endswith('.dat')])))\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "all_beats = []\n",
        "all_labels = []\n",
        "\n",
        "# Process every record\n",
        "for rec_name in tqdm(record_list, desc=\"Segmenting beats\"):\n",
        "    record_path = os.path.join(combined_db_path, rec_name)\n",
        "\n",
        "    try:\n",
        "        # Read ECG signal and annotation\n",
        "        record = wfdb.rdrecord(record_path)\n",
        "        ann = wfdb.rdann(record_path, 'atr')\n",
        "\n",
        "        signal = record.p_signal[:, 0]   # use first ECG channel\n",
        "        fs = record.fs\n",
        "        r_peaks = ann.sample  #gives the indices of consecutive r_peaks\n",
        "\n",
        "        # Find beat boundaries\n",
        "        boundaries = get_beat_boundaries(r_peaks, len(signal))\n",
        "        labels = ann.symbol[1:len(boundaries)+1]\n",
        "\n",
        "        # Segment beats and labels\n",
        "        beats = [signal[start:end] for (start, end) in boundaries]\n",
        "\n",
        "        # Clip to same length\n",
        "        min_len = min(len(beats), len(labels))\n",
        "        beats = beats[:min_len]\n",
        "        labels = labels[:min_len]\n",
        "\n",
        "        # Append to combined dataset\n",
        "        all_beats.extend(beats)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {rec_name}: {e}\")\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array([np.array(b) for b in all_beats], dtype=object)  # variable-length beats\n",
        "y = np.array(all_labels)\n",
        "\n",
        "print(f\"\\nTotal beats: {len(X)}\")\n",
        "print(f\"Unique labels: {set(y)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfYlTsHoO7Rm",
        "outputId": "ad1f4ede-0943-4c24-b984-5d36c90cb972"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Segmenting beats: 100%|██████████| 126/126 [00:05<00:00, 24.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total beats: 300272\n",
            "Unique labels: {np.str_(']'), np.str_('V'), np.str_('R'), np.str_('!'), np.str_('~'), np.str_('B'), np.str_('S'), np.str_('f'), np.str_('Q'), np.str_('L'), np.str_('|'), np.str_('N'), np.str_('+'), np.str_('J'), np.str_('\"'), np.str_('/'), np.str_('F'), np.str_('E'), np.str_('e'), np.str_('A'), np.str_('x'), np.str_('j'), np.str_('a'), np.str_('[')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-processing\n",
        "#Resampling each beat to be 360 points\n",
        "\n",
        "target_len = 360\n",
        "X = np.array([resample(b, target_len) for b in all_beats])\n",
        "le = LabelEncoder()  # initialize encoder\n",
        "Y = le.fit_transform(all_labels) #converts beat labels (symbols) into numeric class IDs.\n",
        "\n",
        "X, Y = shuffle(X, Y, random_state=42)\n",
        "\n",
        "# Remove empty or invalid beats (zero or NaN)\n",
        "clean_beats = []\n",
        "clean_labels = []\n",
        "for b, l in zip(X, Y):\n",
        "    if len(b) == 0:  # empty beat\n",
        "        continue\n",
        "    if np.any(np.isnan(b)) or np.all(b == 0):  # invalid beat\n",
        "        continue\n",
        "    clean_beats.append(b)\n",
        "    clean_labels.append(l)\n",
        "\n",
        "X = np.array(clean_beats)\n",
        "Y = np.array(clean_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "CnqKhYlQZ95l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove rare classes\n",
        "unique, counts = np.unique(Y, return_counts=True)\n",
        "rare_classes = unique[counts < 2]\n",
        "mask = ~np.isin(Y, rare_classes)\n",
        "X = X[mask]\n",
        "Y = Y[mask]\n",
        "\n",
        "\n",
        "#Normalize\n",
        "# Normalize each beat to range [-1, 1]\n",
        "X = np.array([b / np.max(np.abs(b)) if np.max(np.abs(b)) > 0 else b for b in X], dtype=np.float32)\n",
        "X = np.clip(X, -1.0, 1.0)\n",
        "\n",
        "Y = Y.astype(np.int32)\n"
      ],
      "metadata": {
        "id": "5sdPP_iieQ4j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data into training, validation and testing sets\n",
        "# First split: Train + Temp (which we’ll later split into validation and test)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
        "    X, Y, test_size=0.3, random_state=42, stratify=Y\n",
        ")\n",
        "\n",
        "# Second split: Validation + Test\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(\n",
        "    X_temp, Y_temp, test_size=0.5, random_state=42, stratify=Y_temp\n",
        ")\n",
        "\n",
        "# Reshape for CNN (adding the channel dimension)\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_val   = X_val[..., np.newaxis]\n",
        "X_test  = X_test[..., np.newaxis]\n",
        "\n",
        "print(\"Data split complete:\")\n",
        "print(f\"Training set:   {X_train.shape}, labels: {Y_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}, labels: {Y_val.shape}\")\n",
        "print(f\"Testing set:    {X_test.shape}, labels: {Y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbCg-B1rbcod",
        "outputId": "ba9684c6-099b-4100-b0e8-89381dba01b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split complete:\n",
            "Training set:   (210189, 360, 1), labels: (210189,)\n",
            "Validation set: (45041, 360, 1), labels: (45041,)\n",
            "Testing set:    (45041, 360, 1), labels: (45041,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_classes = len(np.unique(Y))\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4, clipnorm = 1.0, epsilon=1e-8)\n",
        "\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(Y_train),\n",
        "    y=Y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "le = LabelEncoder()\n",
        "Y_train = le.fit_transform(Y_train)\n",
        "Y_val   = le.transform(Y_val)\n",
        "Y_test  = le.transform(Y_test)\n",
        "\n",
        "num_classes = len(le.classes_)  # one hot encode y\n",
        "Y_train_cat = to_categorical(Y_train, num_classes=num_classes)\n",
        "Y_val_cat   = to_categorical(Y_val, num_classes=num_classes)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(32, 7, activation='relu', input_shape=(360, 1)),\n",
        "    MaxPooling1D(2),\n",
        "    Conv1D(64, 5, activation='relu'),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')  # num_classes = number of unique labels\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "5n6mBIOBd1_0",
        "outputId": "30856db7-885d-4ea9-9a33-59a99bbfc751"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m354\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m177\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m10,304\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5504\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m704,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)             │         \u001b[38;5;34m2,967\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">354</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5504</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">704,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,967</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m718,167\u001b[0m (2.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">718,167</span> (2.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m718,167\u001b[0m (2.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">718,167</span> (2.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "history = model.fit(\n",
        "    X_train, Y_train_cat,\n",
        "    validation_data=(X_val, Y_val_cat),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights_dict,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVjbDzx0faeQ",
        "outputId": "f72bd619-f86f-40b2-9e5d-f751f71b459f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.4298 - loss: 3.5597 - val_accuracy: 0.6822 - val_loss: 0.9788\n",
            "Epoch 2/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.6625 - loss: 2.6538 - val_accuracy: 0.7708 - val_loss: 0.7592\n",
            "Epoch 3/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 2.2068 - val_accuracy: 0.7900 - val_loss: 0.6913\n",
            "Epoch 4/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.7763 - loss: 2.1952 - val_accuracy: 0.8240 - val_loss: 0.6143\n",
            "Epoch 5/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 2.6329 - val_accuracy: 0.8362 - val_loss: 0.5755\n",
            "Epoch 6/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 2.3915 - val_accuracy: 0.8397 - val_loss: 0.5433\n",
            "Epoch 7/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 2.5158 - val_accuracy: 0.8508 - val_loss: 0.4927\n",
            "Epoch 8/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 2.4903 - val_accuracy: 0.8617 - val_loss: 0.4587\n",
            "Epoch 9/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 2.3137 - val_accuracy: 0.8816 - val_loss: 0.4008\n",
            "Epoch 10/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 1.8365 - val_accuracy: 0.8778 - val_loss: 0.4100\n",
            "Epoch 11/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 1.9916 - val_accuracy: 0.8799 - val_loss: 0.4115\n",
            "Epoch 12/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 2.2125 - val_accuracy: 0.8818 - val_loss: 0.3902\n",
            "Epoch 13/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 1.5596 - val_accuracy: 0.8744 - val_loss: 0.4128\n",
            "Epoch 14/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 2.0911 - val_accuracy: 0.8841 - val_loss: 0.3857\n",
            "Epoch 15/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 1.4338 - val_accuracy: 0.8986 - val_loss: 0.3412\n",
            "Epoch 16/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 1.6467 - val_accuracy: 0.8906 - val_loss: 0.3655\n",
            "Epoch 17/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 1.2706 - val_accuracy: 0.8971 - val_loss: 0.3504\n",
            "Epoch 18/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 1.1697 - val_accuracy: 0.8901 - val_loss: 0.3674\n",
            "Epoch 19/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 1.2634 - val_accuracy: 0.8896 - val_loss: 0.3665\n",
            "Epoch 20/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 1.6170 - val_accuracy: 0.9036 - val_loss: 0.3280\n",
            "Epoch 21/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 1.2991 - val_accuracy: 0.8983 - val_loss: 0.3517\n",
            "Epoch 22/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.9121 - val_accuracy: 0.9053 - val_loss: 0.3261\n",
            "Epoch 23/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 1.4834 - val_accuracy: 0.9108 - val_loss: 0.3094\n",
            "Epoch 24/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 1.3350 - val_accuracy: 0.9112 - val_loss: 0.3035\n",
            "Epoch 25/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 1.1910 - val_accuracy: 0.9163 - val_loss: 0.2926\n",
            "Epoch 26/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 1.5030 - val_accuracy: 0.9084 - val_loss: 0.3202\n",
            "Epoch 27/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8945 - loss: 1.1223 - val_accuracy: 0.9130 - val_loss: 0.3046\n",
            "Epoch 28/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 1.1837 - val_accuracy: 0.9149 - val_loss: 0.3009\n",
            "Epoch 29/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 0.8541 - val_accuracy: 0.9034 - val_loss: 0.3268\n",
            "Epoch 30/30\n",
            "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 1.2356 - val_accuracy: 0.9271 - val_loss: 0.2653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing and Evaluation\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Compute metrics\n",
        "accuracy = accuracy_score(Y_test, y_pred_classes)\n",
        "precision = precision_score(Y_test, y_pred_classes, average='weighted', zero_division=0)\n",
        "recall = recall_score(Y_test, y_pred_classes, average='weighted', zero_division=0)\n",
        "f1 = f1_score(Y_test, y_pred_classes, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-score:  {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "wnhAgboHgDC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19db41d-807e-41ec-cb65-500415760800"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1408/1408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "Accuracy:  0.9269\n",
            "Precision: 0.9432\n",
            "Recall:    0.9269\n",
            "F1-score:  0.9323\n"
          ]
        }
      ]
    }
  ]
}